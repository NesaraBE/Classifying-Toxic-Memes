{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9792c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import mixture, cluster,metrics, neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af27c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a781699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('./data/train.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "  \n",
    "text_list = list() # storing in lists\n",
    "id_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "for json_str in json_list: \n",
    "    result = json.loads(json_str)\n",
    "    id_list.append(f\"{result['id']}\")\n",
    "\n",
    "    text_list.append(f\"{result['text']}\")\n",
    "    labels_list.append(f\"{result['label']}\")\n",
    "\n",
    "with open('./data/test_seen.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list: \n",
    "    result = json.loads(json_str)\n",
    "    id_list.append(f\"{result['id']}\")\n",
    "\n",
    "    text_list.append(f\"{result['text']}\")\n",
    "    labels_list.append(f\"{result['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d515892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({\"id\": id_list, \"text\": text_list}) #converting into dataframes\n",
    "\n",
    "df_label = pd.DataFrame({\"id\": id_list, \"label\": labels_list})\n",
    "\n",
    "df_label_sort = df_label.sort_values(by=\"id\")\n",
    "\n",
    "\n",
    "labels_true = df_label_sort[\"label\"].to_numpy().astype(int)\n",
    "print(labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aecbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"caption_initial.csv\") # saving in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3b71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = list()\n",
    "\n",
    "for i in df['text']:\n",
    "  i = \"[CLS] \" + i + \" [SEP]\"\n",
    "  tokenized_text = tokenizer.tokenize(i)\n",
    "  tokenized_list.append(tokenized_text)\n",
    "\n",
    "indexed_list = list()\n",
    "\n",
    "for i in tokenized_list:\n",
    "  indexed_list.append(tokenizer.convert_tokens_to_ids(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2d1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list = list()\n",
    "\n",
    "for i in tokenized_list:\n",
    "  segment_list.append([1] * len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e8ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "\n",
    "tokens_tensor_list = list()\n",
    "segments_tensor_list = list()\n",
    "\n",
    "for i in indexed_list:\n",
    "  tokens_tensor_list.append(torch.tensor([i]))\n",
    "\n",
    "for i in segment_list:\n",
    "  segments_tensor_list.append(torch.tensor([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822f1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa8fb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "outputs_list = list()\n",
    "hidden_states_list = list() \n",
    "with torch.no_grad():\n",
    "  for (i,j) in zip(tokens_tensor_list,segments_tensor_list):\n",
    "      outputs = model(i,j)\n",
    "      outputs_list.append(outputs)\n",
    "      # Evaluating the model will return a different number of objects based on \n",
    "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "      # becase we set `output_hidden_states = True`, the third item will be the \n",
    "      # hidden states from all layers. See the documentation for more details:\n",
    "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "      hidden_states_list.append(outputs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677ab58",
   "metadata": {},
   "source": [
    "# Fusion Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db2cf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion = [0,2]\n",
    "\n",
    "if(fusion[0] == 0):\n",
    "    layer = 2\n",
    "elif(fusion[0] == 1):\n",
    "    layer = 8\n",
    "else:\n",
    "    layer = 12\n",
    "    \n",
    "if(fusion[1] == 0):\n",
    "    file_name = \"data/006_layer2.pkl\"\n",
    "elif(fusion[1] == 1):\n",
    "    file_name = \"data/008_layer4.pkl\"\n",
    "else:\n",
    "    file_name = \"data/010_fc.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c713913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2 = df2.sort_values(by = \"id\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1119abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_image_in = p.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60331bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = torch.cat(df2[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "data_image = data_image_in.to_numpy()[0:9500,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b28b23",
   "metadata": {},
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27210395",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 10\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2_10 = df2.sort_values(by = \"id\", ascending = True)\n",
    "\n",
    "layer = 11\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2_11 = df2.sort_values(by = \"id\", ascending = True)\n",
    "\n",
    "layer = 12\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2_12 = df2.sort_values(by = \"id\", ascending = True)\n",
    "\n",
    "layer = 13\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2_13 = df2.sort_values(by = \"id\", ascending = True)\n",
    "\n",
    "layer = 7\n",
    "sentence_embedding_list = list()\n",
    "\n",
    "for i in hidden_states_list:\n",
    "  # `token_vecs` is a tensor with shape [22 x 768]\n",
    "  token_vecs = i[layer-1][0][:][:] #first dimension defines the layer of feature extraction\n",
    "\n",
    "  # Calculate the average of all 22 token vectors.\n",
    "  sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "\n",
    "#sort it accordig to id\n",
    "\n",
    "df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list}) #converting into dataframes\n",
    "\n",
    "df2_7 = df2.sort_values(by = \"id\", ascending = True)\n",
    "\n",
    "data_text_7 = torch.cat(df2_7[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "data_text_10 = torch.cat(df2_10[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "data_text_11 = torch.cat(df2_11[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "data_text_12 = torch.cat(df2_12[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "data_text_13 = torch.cat(df2_13[\"features\"].tolist()).numpy().reshape(9500,768)\n",
    "\n",
    "data_text = np.concatenate((data_text_7,data_text_11,data_text_13), axis = 1)\n",
    "# data_text = data_text_9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d86b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "\n",
    "file_name = \"data/010_fc.pkl\"\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_image_in = p.load(f)\n",
    "data_image = data_image_in.to_numpy()[0:9500,1:]\n",
    "\n",
    "# file_name = \"data/008_layer4.pkl\"\n",
    "\n",
    "# with open(file_name, 'rb') as f:\n",
    "#     data_image_in = p.load(f)\n",
    "# data_image_2 = data_image_in.to_numpy()[0:9500,1:]\n",
    "\n",
    "# data_image = np.concatenate((data_image_2,data_image_1), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791f801",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fea1f422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 1767)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Normalization code\n",
    "data_reduced = np.concatenate((data_image,data_text),axis = 1)\n",
    "data_normalized = (data_reduced-np.mean(data_reduced, axis = 0))/(np.var(data_reduced, axis = 0)**0.5+1e-3)\n",
    "print(data_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96d32a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalization code\n",
    "# data_image_red = (data_image-np.mean(data_image))/(np.var(data_image)**0.5+1e-3)\n",
    "# data_text_red = (data_text-np.mean(data_text))/(np.var(data_text)**0.5+1e-3)\n",
    "# data_normalized = np.concatenate((data_image_red,data_text_red),axis = 1)\n",
    "# print(data_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa17bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = data_normalized.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53dd7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_normalized[0:8500,:]\n",
    "y_train = labels_true[0:8500]\n",
    "\n",
    "x_val = data_normalized[8500:9500,:]\n",
    "y_val = labels_true[8500:9500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4bd1d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [data_image[0:8500,:],data_text[0:8500,:]]\n",
    "# y_train = labels_true[0:8500]\n",
    "# input_size1 = data_image.shape[1]\n",
    "# input_size2 = data_text.shape[1]\n",
    "\n",
    "# x_val = [data_image[8500:9500,:],data_text[8500:9500,:]]\n",
    "# y_val = labels_true[8500:9500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b897",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e20179ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def skip_model(input_size):\n",
    "    inp = tf.keras.Input(input_size,)\n",
    "    \n",
    "    dense1 = Dense(256)(inp)\n",
    "    act1 = LeakyReLU(0.1)(dense1)\n",
    "    drop1 = Dropout(0.5)(act1)\n",
    "    \n",
    "    dense2 = Dense(256)(drop1)\n",
    "    act2 = LeakyReLU(0.1)(dense2)\n",
    "    drop2 = Dropout(0.5)(act2)\n",
    "    \n",
    "    skip1 = Add()([drop1, drop2])\n",
    "    \n",
    "    dense3 = Dense(256)(skip1)\n",
    "    act3 = LeakyReLU(0.1)(dense3)\n",
    "    drop3 = Dropout(0.5)(act3)\n",
    "    \n",
    "    skip2 = Add()([drop1, drop3])\n",
    "    \n",
    "    dense4 = Dense(256)(skip2)\n",
    "    act4 = LeakyReLU(0.1)(dense4)\n",
    "    drop4 = Dropout(0.5)(act4)\n",
    "    \n",
    "    skip3 = Add()([drop1, drop4])\n",
    "    \n",
    "    dense5 = Dense(256)(skip3)\n",
    "    act5 = LeakyReLU(0.1)(dense5)\n",
    "    drop5 = Dropout(0.5)(act5)\n",
    "    \n",
    "    skip4 = Add()([drop1, drop5])\n",
    "    \n",
    "#     dense6 = Dense(256)(skip4)\n",
    "#     act6 = LeakyReLU(0.1)(dense6)\n",
    "#     drop6 = Dropout(0.5)(act6)\n",
    "    \n",
    "#     skip5 = Add()([drop1, drop6])\n",
    "    \n",
    "    dense6 = Dense(256)(skip4)\n",
    "    act6 = LeakyReLU(0.1)(dense6)\n",
    "    \n",
    "    out = Dense(1, activation='sigmoid')(act6)\n",
    "    \n",
    "    model = Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85e2ff48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 1767)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 256)          452608      ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_87 (LeakyReLU)     (None, 256)          0           ['dense_105[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 256)          0           ['leaky_re_lu_87[0][0]']         \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 256)          65792       ['dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_88 (LeakyReLU)     (None, 256)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 256)          0           ['leaky_re_lu_88[0][0]']         \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 256)          0           ['dropout_56[0][0]',             \n",
      "                                                                  'dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 256)          65792       ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_89 (LeakyReLU)     (None, 256)          0           ['dense_107[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 256)          0           ['leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 256)          0           ['dropout_56[0][0]',             \n",
      "                                                                  'dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dense_108 (Dense)              (None, 256)          65792       ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_90 (LeakyReLU)     (None, 256)          0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 256)          0           ['leaky_re_lu_90[0][0]']         \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 256)          0           ['dropout_56[0][0]',             \n",
      "                                                                  'dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 256)          65792       ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_91 (LeakyReLU)     (None, 256)          0           ['dense_109[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 256)          0           ['leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 256)          0           ['dropout_56[0][0]',             \n",
      "                                                                  'dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 256)          65792       ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_92 (LeakyReLU)     (None, 256)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            257         ['leaky_re_lu_92[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 781,825\n",
      "Trainable params: 781,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "266/266 [==============================] - 23s 84ms/step - loss: 0.8259 - binary_accuracy: 0.5773 - auc_13: 0.5255 - precision_2: 0.3997 - recall_2: 0.3008 - val_loss: 0.6619 - val_binary_accuracy: 0.5860 - val_auc_13: 0.6278 - val_precision_2: 0.4697 - val_recall_2: 0.5401\n",
      "Epoch 2/15\n",
      "266/266 [==============================] - 21s 78ms/step - loss: 0.6714 - binary_accuracy: 0.6234 - auc_13: 0.5955 - precision_2: 0.4796 - recall_2: 0.2976 - val_loss: 0.6347 - val_binary_accuracy: 0.6570 - val_auc_13: 0.6526 - val_precision_2: 0.6692 - val_recall_2: 0.2248\n",
      "Epoch 3/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.6494 - binary_accuracy: 0.6265 - auc_13: 0.6131 - precision_2: 0.4847 - recall_2: 0.2691 - val_loss: 0.6230 - val_binary_accuracy: 0.6630 - val_auc_13: 0.6813 - val_precision_2: 0.6250 - val_recall_2: 0.3230\n",
      "Epoch 4/15\n",
      "266/266 [==============================] - 22s 82ms/step - loss: 0.6322 - binary_accuracy: 0.6456 - auc_13: 0.6479 - precision_2: 0.5301 - recall_2: 0.3107 - val_loss: 0.6324 - val_binary_accuracy: 0.6380 - val_auc_13: 0.6775 - val_precision_2: 0.5373 - val_recall_2: 0.4651\n",
      "Epoch 5/15\n",
      "266/266 [==============================] - 22s 83ms/step - loss: 0.6140 - binary_accuracy: 0.6673 - auc_13: 0.6769 - precision_2: 0.5779 - recall_2: 0.3491 - val_loss: 0.6103 - val_binary_accuracy: 0.6710 - val_auc_13: 0.6959 - val_precision_2: 0.6526 - val_recall_2: 0.3204\n",
      "Epoch 6/15\n",
      "266/266 [==============================] - 22s 81ms/step - loss: 0.6041 - binary_accuracy: 0.6781 - auc_13: 0.6920 - precision_2: 0.5949 - recall_2: 0.3876 - val_loss: 0.6129 - val_binary_accuracy: 0.6690 - val_auc_13: 0.6993 - val_precision_2: 0.5972 - val_recall_2: 0.4444\n",
      "Epoch 7/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5948 - binary_accuracy: 0.6805 - auc_13: 0.7074 - precision_2: 0.6002 - recall_2: 0.3895 - val_loss: 0.6064 - val_binary_accuracy: 0.6720 - val_auc_13: 0.7023 - val_precision_2: 0.6139 - val_recall_2: 0.4109\n",
      "Epoch 8/15\n",
      "266/266 [==============================] - 21s 80ms/step - loss: 0.5881 - binary_accuracy: 0.6894 - auc_13: 0.7165 - precision_2: 0.6163 - recall_2: 0.4090 - val_loss: 0.6072 - val_binary_accuracy: 0.6690 - val_auc_13: 0.7036 - val_precision_2: 0.5886 - val_recall_2: 0.4806\n",
      "Epoch 9/15\n",
      "266/266 [==============================] - 21s 78ms/step - loss: 0.5843 - binary_accuracy: 0.6932 - auc_13: 0.7217 - precision_2: 0.6212 - recall_2: 0.4218 - val_loss: 0.6033 - val_binary_accuracy: 0.6760 - val_auc_13: 0.7082 - val_precision_2: 0.6113 - val_recall_2: 0.4470\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 21s 78ms/step - loss: 0.5753 - binary_accuracy: 0.7033 - auc_13: 0.7339 - precision_2: 0.6393 - recall_2: 0.4411 - val_loss: 0.6028 - val_binary_accuracy: 0.6790 - val_auc_13: 0.7126 - val_precision_2: 0.5959 - val_recall_2: 0.5297\n",
      "Epoch 11/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5705 - binary_accuracy: 0.7020 - auc_13: 0.7394 - precision_2: 0.6336 - recall_2: 0.4475 - val_loss: 0.6029 - val_binary_accuracy: 0.6810 - val_auc_13: 0.7111 - val_precision_2: 0.5960 - val_recall_2: 0.5452\n",
      "Epoch 12/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5630 - binary_accuracy: 0.7131 - auc_13: 0.7494 - precision_2: 0.6533 - recall_2: 0.4660 - val_loss: 0.6013 - val_binary_accuracy: 0.6790 - val_auc_13: 0.7165 - val_precision_2: 0.5907 - val_recall_2: 0.5556\n",
      "Epoch 13/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5546 - binary_accuracy: 0.7174 - auc_13: 0.7612 - precision_2: 0.6532 - recall_2: 0.4917 - val_loss: 0.5967 - val_binary_accuracy: 0.6870 - val_auc_13: 0.7181 - val_precision_2: 0.6135 - val_recall_2: 0.5168\n",
      "Epoch 14/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5472 - binary_accuracy: 0.7231 - auc_13: 0.7678 - precision_2: 0.6670 - recall_2: 0.4914 - val_loss: 0.5990 - val_binary_accuracy: 0.6900 - val_auc_13: 0.7165 - val_precision_2: 0.6097 - val_recall_2: 0.5530\n",
      "Epoch 15/15\n",
      "266/266 [==============================] - 21s 79ms/step - loss: 0.5409 - binary_accuracy: 0.7305 - auc_13: 0.7746 - precision_2: 0.6758 - recall_2: 0.5115 - val_loss: 0.5971 - val_binary_accuracy: 0.6880 - val_auc_13: 0.7172 - val_precision_2: 0.6068 - val_recall_2: 0.5504\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Add\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD, Adam, schedules\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(tf.keras.Input(input_size,))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(0.1))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model = skip_model(input_size)\n",
    "# model = fusion_model(input_size1, input_size2)\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.9)\n",
    "opt = SGD(learning_rate=0.01)\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "model.summary()\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(x_train,y_train,batch_size=32,epochs=15,validation_data=(x_val, y_val),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62894558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy', 'auc_10', 'val_loss', 'val_binary_accuracy', 'val_auc_10'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0LUlEQVR4nO3deXyU5b338c8vk42sA0mAkAyEsCmEJCqigIKKLIJotVpxt54ea4+K1aNV26etx7bP8WnPo5bap9TjQWq1xbqigBsoghXZlLDvBDIkQBayr5Nczx/3BEKYhEmYyWSS3/v1mtfM3HPfM79gzHeu+7qv6xJjDEoppVRrIYEuQCmlVPekAaGUUsojDQillFIeaUAopZTySANCKaWUR6GBLsCXEhMTTVpaWqDLUEqpoLFp06YiY0ySp9d6VECkpaWxcePGQJehlFJBQ0QOtfWanmJSSinlkQaEUkopjzQglFJKedSj+iCUUj1HQ0MDTqeT2traQJfSI0RGRpKamkpYWJjXx/g1IERkJvB7wAa8bIx5ttXr8cBrwGB3Lf9ljHnFm2OVUj2b0+kkNjaWtLQ0RCTQ5QQ1YwzFxcU4nU6GDh3q9XF+O8UkIjbgj8A1wGjgVhEZ3Wq3B4Adxpgs4Arg/4pIuJfHKqV6sNraWhISEjQcfEBESEhI6HBrzJ99EOOBfcaYA8aYemAxcH2rfQwQK9ZvQAxQAri8PFYp1cNpOPhOZ/4t/RkQKUBei+dO97aWXgTOB/KBrcDDxpgmL48FQETuE5GNIrKxsLCww0XWu5r406r9rNnb8WOVUqon82dAeIqr1otPzAA2A4OAbOBFEYnz8lhrozEvGWPGGWPGJSV5HAzYrjCb8NLq/XyQk9/hY5VSPVdxcTHZ2dlkZ2czcOBAUlJSTj6vr69v99iNGzcyb968Dn1eWloaRUVF51Kyz/mzk9oJOFo8T8VqKbT0feBZY61atE9EDgLneXmsT4gIWQ47OXll/nh7pVSQSkhIYPPmzQA8/fTTxMTE8Nhjj5183eVyERrq+U/ouHHjGDduXFeU6Vf+bEFsAEaIyFARCQfmAu+32ucwMBVARAYAo4ADXh7rM1mpdvYcr6CyzuWvj1BK9QD33HMPjz76KFdeeSVPPPEE69evZ+LEiVxwwQVMnDiR3bt3A7Bq1SquvfZawAqXe++9lyuuuIL09HTmz5/v9ecdOnSIqVOnkpmZydSpUzl8+DAAb775JhkZGWRlZTF58mQAtm/fzvjx48nOziYzM5O9e/ee88/rtxaEMcYlIg8CH2NdqrrQGLNdRO53v74A+BWwSES2Yp1WesIYUwTg6Vh/1ZrtsGMMbDtSxqXpCf76GKVUJ/3HB9vZkV/u0/ccPSiOX84Z0+Hj9uzZw4oVK7DZbJSXl7N69WpCQ0NZsWIFP/3pT3n77bfPOGbXrl18/vnnVFRUMGrUKH70ox95NR7hwQcf5K677uLuu+9m4cKFzJs3j/fee49nnnmGjz/+mJSUFEpLSwFYsGABDz/8MLfffjv19fU0NjZ2+Gdrza/jIIwxy4HlrbYtaPE4H5ju7bH+kuWwA7A5r1QDQinVrptvvhmbzQZAWVkZd999N3v37kVEaGho8HjM7NmziYiIICIigv79+3Ps2DFSU1PP+llr167lnXfeAeDOO+/kJz/5CQCTJk3innvu4Xvf+x433ngjABMmTOA3v/kNTqeTG2+8kREjRpzzz6ojqYF+0eEM7hdFTl5poEtRSnnQmW/6/hIdHX3y8c9//nOuvPJK3n33XXJzc7niiis8HhMREXHysc1mw+Xq3Ons5ktVFyxYwLp161i2bBnZ2dls3ryZ2267jUsuuYRly5YxY8YMXn75Za666qpOfU4znYvJzeqoLg10GUqpIFJWVkZKinUF/qJFi3z+/hMnTmTx4sUAvP7661x22WUA7N+/n0suuYRnnnmGxMRE8vLyOHDgAOnp6cybN4/rrruOLVu2nPPna0C4ZaXGk19Wy/FynfdFKeWdn/zkJzz11FNMmjTJJ+f8MzMzSU1NJTU1lUcffZT58+fzyiuvkJmZyV//+ld+//vfA/D4448zduxYMjIymDx5MllZWbzxxhtkZGSQnZ3Nrl27uOuuu865HrGuMO0Zxo0bZzq7YNCmQyV8909reenOi5g+ZqCPK1NKddTOnTs5//zzA11Gj+Lp31RENhljPF6Tqy0ItzGD4rGFCDnO0kCXopRS3YIGhFtkmI3zBsbqgDmllHLTgGghy2Enx1lKU1PPOe2mlFKdpQHRQrbDTkWti4PFVYEuRSmlAk4DooXs5gFzh0sDWodSSnUHGhAtDEuKITrcph3VSimFjqQ+jS1EGJsarwPmlFIUFxczdepUAI4ePYrNZqN5SYH169cTHh7e7vGrVq0iPDyciRMnnvHaokWL2LhxIy+++KLvC/chDYhWshx2Fn55kDpXIxGhtkCXo5QKkLNN9302q1atIiYmxmNABAs9xdTKBQ47DY3G5zNHKqWC36ZNm5gyZQoXXXQRM2bMoKCgAID58+czevRoMjMzmTt3Lrm5uSxYsIDnn3+e7Oxs1qxZ49X7P/fcc2RkZJCRkcELL7wAQFVVFbNnzyYrK4uMjAzeeOMNAJ588smTn9mR4OoIbUG00jyza05eKRcM7hvYYpRSlg+fhKNbffueA8fCNc96vbsxhoceeoglS5aQlJTEG2+8wc9+9jMWLlzIs88+y8GDB4mIiKC0tBS73c7999/foVbHpk2beOWVV1i3bh3GGC655BKmTJnCgQMHGDRoEMuWLQOs+Z9KSkp499132bVrFyJycspvX9MWRCsD4yLpHxtBjlMHzCmlTqmrq2Pbtm1MmzaN7Oxsfv3rX+N0OgFrDqXbb7+d1157rc1V5s7myy+/5IYbbiA6OpqYmBhuvPFG1qxZw9ixY1mxYgVPPPEEa9asIT4+nri4OCIjI/nBD37AO++8Q1RUlC9/1JO0BdHKqSVISwNdilKqWQe+6fuLMYYxY8awdu3aM15btmwZq1ev5v333+dXv/oV27d3fH2ztubFGzlyJJs2bWL58uU89dRTTJ8+nV/84hesX7+elStXsnjxYl588UU+++yzDn/m2WgLwoNsh50DRVWUVXte/EMp1ftERERQWFh4MiAaGhrYvn07TU1N5OXlceWVV/Lb3/6W0tJSKisriY2NpaKiwuv3nzx5Mu+99x7V1dVUVVXx7rvvcvnll5Ofn09UVBR33HEHjz32GN988w2VlZWUlZUxa9YsXnjhhZOd6b6mLQgPmgfM5ThLmTwyKbDFKKW6hZCQEN566y3mzZtHWVkZLpeLH//4x4wcOZI77riDsrIyjDE88sgj2O125syZw0033cSSJUv4wx/+wOWXX37a+y1atIj33nvv5POvv/6ae+65h/HjxwPwgx/8gAsuuICPP/6Yxx9/nJCQEMLCwvjTn/5ERUUF119/PbW1tRhjeP755/3yM+t03x6U1zaQ+fQn/Pu0kTw09dyX7VNKdZxO9+17Ot23D8RFhjEsKVpHVCulejUNiDZkO/qyOa+szY4jpZTq6TQg2pDtiKeoso4jpTWBLkWpXku/oPlOZ/4tNSDacGrAnI6HUCoQIiMjKS4u1pDwAWMMxcXFREZGdug4vYqpDecNjCM8NIQcZymzM5MDXY5SvU5qaipOp5PCwsJAl9IjREZGkpqa2qFjNCDaEB4awphBcWzWAXNKBURYWBhDhw4NdBm9mp5iakdWqp2tzjJcjU2BLkUppbqcBkQ7sh12ahoa2Xu8MtClKKVUl9OAaEfLmV2VUqq38WtAiMhMEdktIvtE5EkPrz8uIpvdt20i0igi/dyv5YrIVvdr5z48uhPSEqKI7xOmA+aUUr2S3zqpRcQG/BGYBjiBDSLyvjFmR/M+xpjfAb9z7z8HeMQYU9Liba40xhT5q8azaZ7ZdbNe6qqU6oX82YIYD+wzxhwwxtQDi4Hr29n/VuDvfqynU7JT49l9tJzqelegS1FKqS7lz4BIAfJaPHe6t51BRKKAmcDbLTYb4BMR2SQi97X1ISJyn4hsFJGN/rheOsthp8nAtiO6BKlSqnfxZ0CIh21tDYmcA/yz1emlScaYC4FrgAdEZLKnA40xLxljxhljxiUl+X5qbu2oVkr1Vv4MCCfgaPE8FchvY9+5tDq9ZIzJd98fB97FOmXV5RJjIkjt24fN2lGtlOpl/BkQG4ARIjJURMKxQuD91juJSDwwBVjSYlu0iMQ2PwamA9v8WGu7shx2Nh8uDdTHK6VUQPgtIIwxLuBB4GNgJ/APY8x2EblfRO5vsesNwCfGmKoW2wYAX4pIDrAeWGaM+chftZ5NdqqdI6U1FFbUBaoEpZTqcn6di8kYsxxY3mrbglbPFwGLWm07AGT5s7aOaO6H2OIsZer5AwJbjFJKdREdSe2FjJQ4bCGiHdVKqV5FA8ILUeGhjBwQy7caEEqpXkQDwkvZjnhy8kp18RKlVK+hAeGlrFQ75bUucourA12KUkp1CQ0IL2UPtgM6YE4p1XtoQHhpRP9YosJtusKcUqrX0IDwki1EyEiJ14BQSvUaGhAdkO2wsyO/nHqXLkGqlOr5NCA6INthp76xiV1HdWZXpVTPpwHRATqzq1KqN9GA6IBB8ZEkxkTogDmlVK+gAdEBInJywJxSSvV0GhAdlJVqZ39hFeW1DYEuRSml/EoDooOaB8xtdZYFthCllPIzDYgOykyxA+h4CKVUj6cB0UHxUWGkJ0ZrQCilejwNiE7IctjZrDO7KqV6OA2ITsh22CmsqONoeW2gS1FKKb/RgOgEHTCnlOoNNCA64fzkWMJsogPmlFI9mgZEJ0SE2hidHKctCKVUj6YB0UnZDjtbnWU0NmlHtVKqZ9KA6KQsh52q+kb2F1YGuhSllPILDYhOau6o3ny4NKB1KKWUv2hAdNLQhGhiI0PZ7CwNdClKKeUXGhCdFBIiZDvs2lGtlOqxNCDOQVaqnV1HK6htaAx0KUop5XN+DQgRmSkiu0Vkn4g86eH1x0Vks/u2TUQaRaSfN8d2B1kOO41Nhu35OrOrUqrn8VtAiIgN+CNwDTAauFVERrfcxxjzO2NMtjEmG3gK+MIYU+LNsd1BVmo8AN9qR7VSqgfyZwtiPLDPGHPAGFMPLAaub2f/W4G/d/LYgOgfF8mg+EhydG0IpVQP5M+ASAHyWjx3uredQUSigJnA25049j4R2SgiGwsLC8+56I7KHqwd1UqpnsmfASEetrU17HgO8E9jTElHjzXGvGSMGWeMGZeUlNSJMs9NVqqdwyXVlFTVd/lnK6WUP/kzIJyAo8XzVCC/jX3ncur0UkePDSid2VUp1VP5MyA2ACNEZKiIhGOFwPutdxKReGAKsKSjx3YHY1PiCRFdglQp1fOE+uuNjTEuEXkQ+BiwAQuNMdtF5H736wvcu94AfGKMqTrbsf6q9VxER4QyckAsOTqiWinVw/gtIACMMcuB5a22LWj1fBGwyJtju6usVDuf7DiKMQYRT90nSikVfHQktQ9kOeycqG7gcEl1oEtRSimf0YDwgSyHNWBO+yGUUj2JBoQPjBoQS2RYCDl5OmBOKdVzaED4QKgthLEp8dpRrZTqUTQgfCQr1c62I2U0NDYFuhSllPIJDQgfyXLYqXM1sftoRaBLUUopn9CA8JHs5iVItaNaKdVDaED4SGrfPiREh+uUG0qpHkMDwkdEhCyHXTuqlVI9hgaED2Wl2tl7vJKK2oZAl6KUUudMA8KHshzxGANbj+h4CKVU8NOA8KHsk1N/a0AopYKfBoQP2aPCSUuI0o5qpVSP4FVAiEi0iIS4H48UketEJMy/pQWnLIddL3VVSvUI3rYgVgORIpICrAS+j4cpupXVUX20vJajZbWBLkUppc6JtwEhxphq4EbgD8aYG4DR/isreGUPtgPo5a5KqaDndUCIyATgdmCZe5tfFxsKVqOT4wgNEe2HUEoFPW8D4sfAU8C77mVD04HP/VZVEIsMs3F+cpy2IJRSQc+rVoAx5gvgCwB3Z3WRMWaePwsLZlmOeJZ8m09TkyEkRJcgVUoFJ2+vYvqbiMSJSDSwA9gtIo/7t7Tgle3oS0WdiwNFlYEuRSmlOs3bU0yjjTHlwHeA5cBg4E5/FRXssk8uQaoD5pRSwcvbgAhzj3v4DrDEGNMAGL9VFeTSE2OIiQjVjmqlVFDzNiD+DOQC0cBqERkClPurqGAXEiJkpsbrgDmlVFDzKiCMMfONMSnGmFnGcgi40s+1BbVsh52dBeXUNjQGuhSllOoUbzup40XkORHZ6L79X6zWhGpDlsOOq8nw+rrDGKNn45RSwcfbU0wLgQrge+5bOfCKv4rqCaaMTOLS9H78aukO7l20gWPlOvWGUiq4eBsQw4wxvzTGHHDf/gNI92dhwS4yzMbffnApv5wzmrUHipn23Be8+61TWxNKqaDhbUDUiMhlzU9EZBJQc7aDRGSmiOwWkX0i8mQb+1whIptFZLuIfNFie66IbHW/ttHLOruVkBDh+5OG8uHDkxkxIJZH3sjhvr9uorCiLtClKaXUWYk332hFJAt4FYh3bzoB3G2M2dLOMTZgDzANcAIbgFuNMTta7GMHvgJmGmMOi0h/Y8xx92u5wDhjTJG3P8y4cePMxo3dM0samwwLvzzI7z7ZTXS4jWeuz2BO1qBAl6WU6uVEZJMxZpyn17y9iinHGJMFZAKZxpgLgKvOcth4YJ/7lFQ9sBi4vtU+twHvGGMOuz/nuDf1BCNbiPCvk9NZPu9yBidE89Dfv+WB17+huFJbE0qp7qlDK8oZY8rdI6oBHj3L7ilAXovnTve2lkYCfUVklYhsEpG7Wn4c8Il7+31tfYiI3Nd8dVVhYaGXP0ngDO8fw9v3T+AnM0fx6Y5jTH9+NR9tKwh0WUopdYZzWXL0bLPQeXq99fmsUOAiYDYwA/i5iIx0vzbJGHMhcA3wgIhM9vQhxpiXjDHjjDHjkpKSvK8+gEJtIfzbFcP54KHLGBgfyf2vfcPDi7+ltLo+0KUppdRJ5xIQZ+u8cAKOFs9TgXwP+3xkjKly9zWsBrIAjDH57vvjwLtYp6x6lFEDY3nvgUk8cvVIlm0pYNrzq1m581igy1JKKeAsASEiFSJS7uFWAZyth3UDMEJEhopIODAXeL/VPkuAy0UkVESigEuAne41sGPdNUQD04Ftnfj5ur0wWwgPXz2C9x6YREJ0OP/yl4089mYOZTUNgS5NKdXLtbsehDEmtrNvbIxxiciDwMeADVjoXmzofvfrC4wxO0XkI2AL0AS8bIzZ5l6Q6F0Raa7xb8aYjzpbSzDISInn/QcvY/7Kvfzpi/38c18Rz343kykjg+O0mVKq5/HqMtdg0Z0vc+2InLxS/v3NHPYdr+TW8Q5+Nns0MRG6wqtSyvfO+TJX1bWyHHaWPnQZP5ySzhsb8pjx/Gq+2uf1cBCllPIJDQiAgi3QcNaB4V0qMszGU9ecz5v3TyQ8NITbXl7HL5Zso7reFejSlFK9hAZEdQksuhb+fivUVwe6mjNcNKQvy+ddzr2ThvLXrw8x84U1rD9YEuiylFK9gAZEVD+45lk4sAr+fku3DIk+4TZ+MWc0i//1UgBueWktv1yyjco6bU0opfxHAwIg+za44c+Q+yX87XtQXxXoijy6JD2BDx++nLsnpPHq14eY8fxqVu/p/qPHlVLBSQOiWdYtcMNLcOif8PrNUFcZ6Io8io4I5enrxvDmDycQGRbCXQvXW+MmqnXchFLKtzQgWsq8Gb77Mhz+Gl6/CeoqAl1Rm8al9WPZvMt54MphvPvtEa5+/gud00kp5VMaEK1lfBdu+h/IWw+vfRdqy89+TFdpqIGlj8D8C6BoL5FhNh6fcR5LHphEUkwE97/2Df/2+iaOV+jqdUqpc6cB4cmYG+DmRXBkE7x2I9SWBboiKNoHL18NGxdCVRH85TooOQhYo7CXPDiJx2eMYsXO40x7bjVvb9LV65RS50YDoi2jr4Ob/wL5m+GvN0BNaeBq2foWvDQFyvPh9rfg+x+CqwZevQ7KnIA1p9MDVw5n+bzLGd4/hn9/M4d7XtnAkdLuNb5DKRU8NCDac/61cMtfrYF0f/0O1Jzo2s9vqLVOKb39LzAgA+7/EkZMg4EZcMc7Vmj95TqoODUD7PD+Mbz5wwk8PWc0G3JLmP7cF/x1bS5NTdqaUEp1jAbE2Yy6Bua+Dse2w6vXWwPrukLx/lOnlC57BO5ZCvEt1ltKuRBufxMqCqzwqio++VJIiHDPpKF8/OPJXDikLz9fsp25L33NgcLueWWWUqp70oDwxsgZMPdvcHyXdVrH3yGx7W3482QoPwK3vQlXPw22sDP3G3wp3LrYCpPXzjwN5ugXxav3jue3N2Wy62g51/x+DQu+2I+rscm/9SulegQNCG+NmAa3/g2K9lqndVp8Y/eZ5lNKb90LA8bA/Wtg5PT2j0mfAre8Bsd2eLw0V0T43jgHKx6dwhWjknj2w13c8P++YmdBN7o6SynVLWlAdMTwq93f2PfCX+ZYVxP5SvF++B/3KaVJP4Z7lkF8qnfHjpwONy2EI9+0OadU/7hIFtxxEX+87UIKymqY84cvee6T3dS5Gn33MyilehQNiI4adiXc9g8oOWBN8ld5/Nzfc9vb8Ocp1hVJt70J0/7D8yml9oy+7tR0IW/cAa66M3YREWZnJvPpI1O4LmsQ8z/bx7Xzv+Sbw13c+a6UCgoaEJ2RPsXqIC49ZIVERSfXkW6ohaWPuk8pjbauUjrbKaX2ZN4M182H/Svhze9Do+fpN/pGh/PcLdm8cs/FVNa5+O6fvuJXS3foVOJKqdPoinLnItc9b1N8Ctz9AcQO9P7Y4v3w5t1wdCtMehiu+nnHWw1tWfdn+PAn1qjwG/8bQmxt7lpR28D/+WgXr319mMSYcOZePJjbLx1Mcnwf39SilOrW2ltRTgPiXB1aa3UOxw60QiJu0NmP2fYOvD8PbKHWaaGRM3xf15cvwIpfQvbtcN2LENJ+Y3FjbgkLvtjPyl3HCRFh+ugB3DlhCBPSE3CvDa6U6oE0IPzt8Dpr3qaYJLi71XiFlhpq4ZOfwYaXIXU83PyK9x3RnfH5f8IXz8LFP4BZ/wVe/KHPK6nmta8P8cbGPEqrGxjRP4a7JqZxwwUpui62Uj2QBkRXyNtgzdsUleAe1NbqD3/xfnjzHji6BSbOg6m/8N0ppbYYA5/+Ar6aDxMehOm/9iokAGobGnk/J59X1+ay7Ug5MRGh3HRRKndOGMKwpBj/1q2U6jIaEF3Fucmat6mP3QoJ+2Br+/Z3YclDVl/ADQus0dldxRhY/jhs+G+Y8gRc+dMOHm74Nq+UV7/KZdnWAhoaDZePSOTOS4cw9fwB2EL09JNSwUwDoisd+caa+iIy3povad2frT/OqRfDTa+A3dH1NTU1wfsPwebXrFHZlz3SqbcprKjjjQ2Hee3rwxwtryXF3ofbLx3M3IsH0y863Lc1K6W6hAZEV8vfbM3bVFsGGJj4EEz9pf9PKbWnqRHe+VdrzMU1v4VLftjpt3I1NvHpjmO8uvYQaw8UEx4awpzMQdw1YQhZDrvvalZK+Z0GRCAU5MDHP4MJD3TtKaX2NDZY/SC7lsKc+XDR3ef8lnuOVfDq2lze+eYI1fWNZDns3D1hCLPGJhMZ1vbltUqp7kEDQp3iqoPFt8G+lXDjS5D5PZ+8bXltA+9scvLq14c4UFhFv+hw5l7s4PZLh5Bi1zEVSnVXGhDqdA011gC/Q19Zl9qOvt5nb22M4Z/7ivnL2lxW7rRGmE8ansjsscnMGDOQvtpXoVS3ErCAEJGZwO8BG/CyMeZZD/tcAbwAhAFFxpgp3h7bmgZEB9RVWldc5X9rrXfhh8F6zhPV/H39YT7IKeBwSTW2EGHS8ESuHZvM9DEDsEdpWCgVaAEJCBGxAXuAaYAT2ADcaozZ0WIfO/AVMNMYc1hE+htjjntzrCcaEB1UU2qtb3F8F9z+D0i/wi8fY4xhe345S7cUsGxrPnklNYS6w2J2ZjIzRg8kPiqAHfhK9WKBCogJwNPGmBnu508BGGP+s8U+/wYMMsb8r44e64kGRCdUl8Ci2XAi1xptnTDMGuwXlQCR9rNO0dFRxhi2HSln6dZ8lm0pwHnCCovLRlinoaZrWCjVpdoLCH/OnZAC5LV47gQuabXPSCBMRFYBscDvjTGvenksACJyH3AfwODBg31SeK8S1Q/ufM8KiSX/dvprYjsVFtGJp99HJUJ0QovH7u1nuZRXRBibGs/Y1HienHkeW4+UsWxLAUu3FPD47i381LaVy4YnMjtzENNGDyC+j4aFUoHiz4DwNMS2dXMlFLgImAr0AdaKyNdeHmttNOYl4CWwWhCdrrY3ix1grV5XuBuqi6zV8qqL3Y+L3I+LrXW5q4ugpp31IyLi3cHRHCgJEB4LYZEQFgVhfSDUeixhkWSGRZE5KpInM6LYWxzOZwcq+WTPQX6zez/P2CK4eHgKszJTuDqYw6K+GiTE+jdQKoj4MyCcQMthw6lAvod9iowxVUCViKwGsrw8VvlSWB8YlO3dvo0uKyROC5DmYHE/ryqCsjwo2Az1VdBQDU1trzchWM3JkcD9AM1/Sw9BXW4YNe+HcyI0krDIaPpExWLrEwcpF8GQSTBkAvTpew4/vI81Nlgj6g+ssm7ODRAaAefNhoybrEWnAjloUikv+bMPIhSro3kqcASro/k2Y8z2FvucD7wIzADCgfXAXGDX2Y71RPsgurnGBusSW1etFRgN7vvTnteAq8a6b6jBNFRzrKSUvGPFFBSdwDTUECUNDOlTw7CGPdia6gGBgWMh7XJImwSDJ1inzrqKMXB8Jxz8wgqE3C+hvtKqa1A2DJ0CNSWwY4k1ur5PP+vS4rE3weCJPu/nUaojAnmZ6yysS1htwEJjzG9E5H4AY8wC9z6PA98HmrAuZ32hrWPP9nkaED1bU5M1ceDyrQUs21LAifJyxoUe5JakQ0wM3UXCic2IqxYrMDJgyGWQdhkMmej7wChzulsIX1jBUOleVbDfMOtqsPQpVmC1/FxXnTVAcdtbsPtDKxTjUmDMDVZYJGd7PduuUr6iA+VUj9PUZNh0+ARLc/JZtvUoRZV1xIU1cW9aCbPj9pFelYPNud5qjQAMyHCHxSTrFp3QsQ+sOQEH11ihcPALKN5nbY9OsgJh6BQrFOxeXihRX2WFxNa3YN8KaGqwwmXsTdZpqKSRHatPqU7SgFA9WmOTYd3BYpZuKeCjbUcpqaonNiKUmef1ZW5qIVmN2wk9/E9rYafmwOg/xjod1Rwa0Ymnv2lDLeR9faqVULAZTBOERVvHNLcS+o8+92/91SWw8wOrZXFwDWCsU2YZN1nLxgZiBmDlH656CO1eA0Q1IFSv0dDYxNr9xXyQk8/H249SXusivk8YM8YMYM6YRCb0OUTo4a+sfoK8ddZpHoCk860//DEDIHeN9ZqrFkJCrana06+wbikX+beDueKotX7I1rfgiPt32XGp1bIY/R1r1UIVPFx11pQ2+1bA3k+haA8kZ8HwqTBsKjjGB/yCBQ0I1SvVu5pYs7eQpVsK+HTHMSrrXPSLDueajIFcmzmI8YNjsB3NsQIh90urhdFQZbUumgNhyASIiA3MD1By0JqefdvbcHyHNS4lfYrVsjj/WmvNEdX9lB62wmDfCqv12VAFtnCrpTpwLOStt65sM43WJeBDJ8Pwq6zA6De0y8vVgFC9Xm1DI6t2F7J0Sz4rdx6npqGRpNgIZo9N5trMZC4c3JcQ44K6iq69Aspbx7ZbrYptb0PpIbBFwIhp1lVSsckQO9B9n2xd8qud3V3HVQ+HvzoVCoW7rO32wTB8mvXfaehkCI8+dUxNKRxcDftXwr7PoOywtb1fuhUUw6daFzlE+H95Xw0IpVqornfx2a7jfJCTz+e7C6l3NTEoPpJZY5O5NmsQWanxSHf9A2sMODda/RU73ocKD8ODbOEtAqOd+4i44A2SpiaoOm5dTSZiXQ0W3b/rLhkuzYN9n8LeFdZFC/WV7lbCRBgx3QqGxBHe/fsaY130sG+lFRi5X1qnPkPCYPClMOwqKzAGjPXLz6cBoVQbKmobWLHzGEtzCli9t5CGRkOKvQ+zxg7kmrHJXOCwd9+wAKszvfKo1XdRUdDG/VGoKz/z2LAoz8ERM7DFNCruW1gXr+nhqofyI9Zgy9K8FveHrfvyI9BYf/oxIaEQOwjiUyBukBUacSktnqdaV5115o+sqx4Orz0VCoU7re3xg60WwohpvvvG76pzf9ZK2P8ZHNtmbY9OssJi2FTr3kf9URoQSnmhrLqBT3ceY/nWAta4w2JQfCQzM5KZnTmQCxx9CQnpxmHRnrpKa6xGmyHivm/utG8tLMo9fUq/04MjKqHtbe11vtZVWN/+W/7RbxkGFUc5Y3admIHWFV3xjlP38Q7r6rLyI+5bvnUrc1r3jXWnv0dIGMQlnwqPuEEQn3p6oDSHSJmzRV/CqtNbCc2njhJH+r8VVnHUCop9K+HA59ZMBQADM1t0dl/S6aujNCCU6qCymgZW7jzG8q1HWb2nkPrGJgbERXBNRjKzxiZz0ZC+2II1LNpijNXSqDh2av6tdm8lnlsmzSLjTw8NCTkVArWlp+8bEmZ90493WOfu4x3WH+6TQZBqTVfS0Z+nutjdEjlyeoiUtXjsKUSi+p0a/Bg/GEZcbYXC0Mld0i/QpqYmOJpzqnWRt86awiY6CR7dBbaOz56kAaHUOaiobeCzXcdZtqWAVXusPouk2AiuyRjINRnJjB/ar+eFhbdc9W2Hx8nH7vm5mhqtP/TxqacHgd1hXV4cEoA1zNsKkcrj0P98qz+hK1oJnVVbbl2FV+aES37YqbfQgFDKRyrrrA7uD7cW8Pnu49Q2NJEYE8HMjAHMcodFqE3nVlLBQwNCKT+oqnOxanchy7cW8Nku69LZhOhwpo8ZyKyxA5mQnqBhobo9DQil/KymvpFVu4+zfNtRVu48RnV9I32jwpg+eiCzMpOZOCyBMA0L1Q1pQCjVhWobGvliTyEfbi1gxc7jVNa5SIwJ57sXpvK9ix0MSwpgJ6dSrWhAKBUgtQ2NrN5TyNvfOFm58ziuJsP4tH7ccrGDWWOT6RMegI5ZpVrQgFCqGzheUcs73xzhjQ15HCyqIjYylO9kp3DLxQ4yUnReJRUYGhBKdSPGGNYfLGHxhjyWby2gztVERkoct1w8mOuzBxEXqcuRqq6jAaFUN1VW3cCSnCP8fX0eOwvKiQwLYdbYZOZePJiL0/p272k+VI+gAaFUN2eMYduRchZvOMySzflU1rlIT4pm7sUObrwwlcSYDo4iVspLGhBKBZHqehfLthTwxoY8Nh46QWiIMG30AG652MHlI5J676ht5RcaEEoFqX3HK3hjQx5vf3OEkqp6BsVHcvM4BzePSyW1b1Sgy1M9gAaEUkGu3tXEip3HWLwhjzV7CwG4fEQSl6b3Y1hSDMOSohncL5rwUB2MpzqmvYDo+NR/SqkuFx5qdV7PGpuM80Q1b2508s63TlbvKTy5jy1EGNwvivTEaIb1jyE9MZp0d3j0iw7XDm/VYdqCUCqIVdQ2cKCwigNFlRworGJ/YaX7eRX1rqaT+8X3CSM9KZphSTGkJ0WTnhjD8P7a6lDaglCqx4qNDCPLYSfLYT9te2OTIb+0hv2FlewvrOKAOzhW7ynkrU3Ok/vZQgRH3z6ngiMphuH9YxidHEd0hP556O30N0CpHsgWIjj6ReHoF8UVo05/raK2gYNFLVob7pbHl/uKqHO3OkIERvSPJcsRbwVQqp1RA2N1wsFeRgNCqV4mNjKMzFQ7man207Y3tzr2HKtgi7OMHGcpn+44xj82Wi2OiNAQxgyKOxkYWQ47aQlR2rfRg2kfhFKqTcYYnCdq2JxXSk5eKTnOUrYdKaemoRGw+jYyU+NPBkaWI57+sZEBrlp1RMD6IERkJvB7wAa8bIx5ttXrVwBLgIPuTe8YY55xv5YLVACNgKutH0Ap5T8ip05VzckaBICrsYm9xytPBkZOXhl/+mI/jU3Wl81B8ZFktgiMsSnxxOr8UkHJbwEhIjbgj8A0wAlsEJH3jTE7Wu26xhhzbRtvc6UxpshfNSqlOi7UFsL5yXGcnxzH3PGDAWvBpO35ZWzOKz15euqj7UcBaznnYUkxjBkUh6NvFKl9+5Dqvk+2RxIRqlOed1f+bEGMB/YZYw4AiMhi4HqgdUAopYJcn3Ab49L6MS6t38ltJ6rqyXG6AyOvlI25J1i6peBkSwOs8OgfG3EyMFqGR2rfKAZpgASUPwMiBchr8dwJXOJhvwkikgPkA48ZY7a7txvgExExwJ+NMS/5sVallI/1jQ7nilH9uWJU/5PbXI1NHC2vxXmixn2r5oj78TeHzwwQgAFxEaTYTw+O5jAZZO9DZJgGiL/4MyA8XdrQukf8G2CIMaZSRGYB7wEj3K9NMsbki0h/4FMR2WWMWX3Gh4jcB9wHMHjwYJ8Vr5TyvVBbiPsPvOd5pFyNTRyrqMNZUo3zRA1HSq0Qae4oX761AFerAElPjGbCsAQmDkvk0vR+JOjMtz7jt6uYRGQC8LQxZob7+VMAxpj/bOeYXGBc634HEXkaqDTG/Fd7n6lXMSnVszU2GY6V154MjrwSKzjWHSimqt66suq8gbFMHJbIxGEJjE/vpwswnUWgrmLaAIwQkaHAEWAucFurwgYCx4wxRkTGAyFAsYhEAyHGmAr34+nAM36sVSkVBGwhwiC7dWrp4hb9HQ2NTWw9Usba/cV8tb+I19cdYuE/DxIiMDbVzsRhCUwclsC4If10HfAO8Os4CPdpoxewLnNdaIz5jYjcD2CMWSAiDwI/AlxADfCoMeYrEUkH3nW/TSjwN2PMb872edqCUEoB1DY08u3hUtbuL+Kr/cVszivF1WQIswkXDO7rDoxEsh32Xj8XlU73rZTq1arqXGzILXG3MIrZll+GMdAnzMa4tL4nT0llpMT3ugWZNCCUUqqFsuoG1h20wmLt/mJ2H6sAIDYylEuGWqejpo0egKNfz1+USQNCKaXaUVhRx9cHmgOjiNziagCyHHbmZCZzbeYgBsb3zClENCCUUqoD8kqqWba1gKVb8tl2pBwRuHhIP+ZkJXPN2GQSe9CltBoQSinVSQcKK1m6pYAPcvLZe7ySEIGJwxK5NjOZmRkDsUeFB7rEc6IBoZRSPrD7aAVLt+TzQU4+ucXVhIYIk0cmcW1mMtNGDwjKSQk1IJRSyoeMMWw7Us7SLfks3VLAkdIawkNDuHJUEnOyBjH1vAFBM95CA0Ippfykqcnwbd4JPsgpYNnWAgor6ogKtzH1/AHMyUxmyqikbj3hoAaEUkp1gcYmw/qDJXywJZ8PtxZworqB2MhQpo8eyJysZCYNT+x2y7ZqQCilVBdraGziq/3FfJCTz8fbj1JR6yI2IpRh/WMYmhjNkIQo9300aQlRAevs1oBQSqkAqnM1snpPEat2Hye3uIrcomryy2po+efXHhXGkIRohiZEWaGRGEVaQjRpCdH0jfZfeARsyVGllFIQEWpj2ugBTBs94OS22oZGnCeqOVhUzaHiKg4WVXGouJoNuSdYkpN/WnjE9wkjLSGKtBYtjrREd3hEhSHin+lBNCCUUioAIsNsDO8fy/D+sWe8VudqJK+khtyiKqvFUWyFx6ZDJ/ggJ5+WS2LERYZy3sA43vjhpT4PCg0IpZTqZiJCbQzvH8Pw/jFnvFbnasR5ojk8qsktqqKhsckvrQgNCKWUCiIRoTaGJcUwLOnM8PC17nW9lVJKqW5DA0IppZRHGhBKKaU80oBQSinlkQaEUkopjzQglFJKeaQBoZRSyiMNCKWUUh71qMn6RKQQONTJwxOBIh+W40/BVCsEV73BVCsEV73BVCsEV73nUusQY0ySpxd6VECcCxHZ2NaMht1NMNUKwVVvMNUKwVVvMNUKwVWvv2rVU0xKKaU80oBQSinlkQbEKS8FuoAOCKZaIbjqDaZaIbjqDaZaIbjq9Uut2gehlFLKI21BKKWU8kgDQimllEe9PiBEZKaI7BaRfSLyZKDraY+IOETkcxHZKSLbReThQNd0NiJiE5FvRWRpoGs5GxGxi8hbIrLL/W88IdA1tUVEHnH/DmwTkb+LSGSga2pJRBaKyHER2dZiWz8R+VRE9rrv+wayxmZt1Po79+/BFhF5V0TsASzxNJ7qbfHaYyJiRCTRF5/VqwNCRGzAH4FrgNHArSIyOrBVtcsF/Lsx5nzgUuCBbl4vwMPAzkAX4aXfAx8ZY84DsuimdYtICjAPGGeMyQBswNzAVnWGRcDMVtueBFYaY0YAK93Pu4NFnFnrp0CGMSYT2AM81dVFtWMRZ9aLiDiAacBhX31Qrw4IYDywzxhzwBhTDywGrg9wTW0yxhQYY75xP67A+gOWEtiq2iYiqcBs4OVA13I2IhIHTAb+B8AYU2+MKQ1oUe0LBfqISCgQBeQHuJ7TGGNWAyWtNl8P/MX9+C/Ad7qyprZ4qtUY84kxxuV++jWQ2uWFtaGNf1uA54GfAD678qi3B0QKkNfiuZNu/Ae3JRFJAy4A1gW4lPa8gPUL2xTgOryRDhQCr7hPib0sItGBLsoTY8wR4L+wvikWAGXGmE8CW5VXBhhjCsD6sgP0D3A93roX+DDQRbRHRK4Djhhjcnz5vr09IMTDtm5/3a+IxABvAz82xpQHuh5PRORa4LgxZlOga/FSKHAh8CdjzAVAFd3nFMhp3OfurweGAoOAaBG5I7BV9Uwi8jOsU7uvB7qWtohIFPAz4Be+fu/eHhBOwNHieSrdrKnemoiEYYXD68aYdwJdTzsmAdeJSC7WqburROS1wJbULifgNMY0t8jewgqM7uhq4KAxptAY0wC8A0wMcE3eOCYiyQDu++MBrqddInI3cC1wu+neA8aGYX1ZyHH//5YKfCMiA8/1jXt7QGwARojIUBEJx+roez/ANbVJRATrHPlOY8xzga6nPcaYp4wxqcaYNKx/18+MMd32W64x5iiQJyKj3JumAjsCWFJ7DgOXikiU+3diKt20Q72V94G73Y/vBpYEsJZ2ichM4AngOmNMdaDraY8xZqsxpr8xJs39/5sTuND9O31OenVAuDuhHgQ+xvof7B/GmO2Brapdk4A7sb6Nb3bfZgW6qB7kIeB1EdkCZAP/O7DleOZu5bwFfANsxfr/uFtNCyEifwfWAqNExCki/wI8C0wTkb1YV9s8G8gam7VR64tALPCp+/+zBQEtsoU26vXPZ3XvlpNSSqlA6dUtCKWUUm3TgFBKKeWRBoRSSimPNCCUUkp5pAGhlFLKIw0Ipc5CRBpbXFa82Zez/opImqdZOZXqDkIDXYBSQaDGGJMd6CKU6mraglCqk0QkV0T+j4isd9+Gu7cPEZGV7rUEVorIYPf2Ae61BXLct+bpMWwi8t/u9R0+EZE+7v3nicgO9/ssDtCPqXoxDQilzq5Pq1NMt7R4rdwYMx5r5O0L7m0vAq+61xJ4HZjv3j4f+MIYk4U1z1PzqP0RwB+NMWOAUuC77u1PAhe43+d+//xoSrVNR1IrdRYiUmmMifGwPRe4yhhzwD2J4lFjTIKIFAHJxpgG9/YCY0yiiBQCqcaYuhbvkQZ86l5EBxF5AggzxvxaRD4CKoH3gPeMMZV+/lGVOo22IJQ6N6aNx23t40ldi8eNnOobnI214uFFwCb34kBKdRkNCKXOzS0t7te6H3/FqSVAbwe+dD9eCfwITq7VHdfWm4pICOAwxnyOteiSHTijFaOUP+k3EqXOro+IbG7x/CNjTPOlrhEisg7ry9at7m3zgIUi8jjWKnXfd29/GHjJPftmI1ZYFLTxmTbgNRGJx1rY6vluvgSq6oG0D0KpTnL3QYwzxhQFuhal/EFPMSmllPJIWxBKKaU80haEUkopjzQglFJKeaQBoZRSyiMNCKWUUh5pQCillPLo/wMQJ/CntiDkUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "print(history.history.keys())\n",
    "x = np.arange(15)\n",
    "# pyplot.plot(x, history.history[\"loss\"],x, history.history[\"val_loss\"])\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(history.history[\"loss\"], label='Train Loss')\n",
    "line2, = ax.plot(history.history[\"val_loss\"], label='Test Loss')\n",
    "ax.legend(handles=[line1, line2])\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c1db373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6234788298606873, 0.674677848815918, 0.695644736289978, 0.7067942023277283, 0.7036222219467163, 0.6903376579284668, 0.6961990594863892, 0.6780901551246643, 0.6717861294746399, 0.6782419085502625, 0.6604027152061462, 0.6675813794136047, 0.6702538728713989, 0.6698281764984131, 0.6683759689331055]\n"
     ]
    }
   ],
   "source": [
    "print(history.history[\"val_auc_7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21822327",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_list= []\n",
    "for layer in range(13):\n",
    "    sentence_embedding_list = list()\n",
    "    for i in hidden_states_list:\n",
    "        token_vecs = i[layer-1][0][:][:]\n",
    "        sentence_embedding_list.append(torch.mean(token_vecs, dim=0))\n",
    "    df2 = pd.DataFrame({\"id\": id_list, \"features\": sentence_embedding_list})\n",
    "    df2 = df2.sort_values(by = \"id\", ascending = True)\n",
    "    data_text_list.append(torch.cat(df2_11[\"features\"].tolist()).numpy().reshape(9500,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579c975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_models = 10\n",
    "\n",
    "test_out_prob = []\n",
    "hist = []\n",
    "for i in range(num_models):\n",
    "    num_feat = 3\n",
    "    feautre_idx = np.random.choice(np.arange(13), size = num_feat)\n",
    "    print(feautre_idx)\n",
    "    data_concat = data_text_list[feautre_idx[0]]\n",
    "    for i in range(num_feat-1):\n",
    "        data_concat = np.concatenate((data_concat,data_text_list[feautre_idx[i+1]]), axis = 1)\n",
    "    data_reduced = np.concatenate((data_image,data_concat),axis = 1)\n",
    "    data_normalized = (data_reduced-np.mean(data_reduced, axis = 0))/(np.var(data_reduced, axis = 0)**0.5+1e-3)\n",
    "    \n",
    "    x_train = data_normalized[0:8500,:]\n",
    "    y_train = labels_true[0:8500]\n",
    "\n",
    "    x_val = data_normalized[8500:9500,:]\n",
    "    y_val = labels_true[8500:9500]\n",
    "    input_size = data_normalized.shape[1]\n",
    "    model = skip_model(input_size)\n",
    "    \n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=4,verbose=1,mode=\"auto\",baseline=None,restore_best_weights=False)\n",
    "    \n",
    "    model.compile(optimizer=SGD(learning_rate=0.005), loss=tf.keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "\n",
    "    print(\"Fit model on training data\")\n",
    "    history = model.fit(x_train,y_train,batch_size=32,epochs=30,validation_data=(x_val, y_val), callbacks=[callback])\n",
    "    hist.append(history)\n",
    "    test_out_prob.append(model(x_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_prob_array = np.array(test_out_prob)\n",
    "final_out = np.mean(test_out_prob, axis = 0)\n",
    "final_score = metrics.roc_auc_score(y_val, final_out)\n",
    "print(\"Val AUROC Score\",final_score)\n",
    "final_score = metrics.accuracy_score(y_val, np.rint(final_out))\n",
    "print(\"Val Accuracy\",final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ee4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e638f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(np.floor(13*np.random.rand()))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56211fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fusion_model(input_size1, input_size2):\n",
    "    inp1 = tf.keras.Input(input_size1,)\n",
    "    inp2 = tf.keras.Input(input_size2,)\n",
    "    \n",
    "    conv1 = Conv2D(32,(3,3),padding=\"same\")(inp1)\n",
    "    lrelu1 = LeakyReLU(0.1)(conv1)\n",
    "    max_pool1 = \n",
    "    self.model.add(MaxPooling2D())\n",
    "    \n",
    "    inp = Concatenate()([inp1,inp2])\n",
    "    dense1 = Dense(256)(inp)\n",
    "    act1 = LeakyReLU(0.1)(dense1)\n",
    "    drop1 = Dropout(0.5)(act1)\n",
    "    \n",
    "    dense2 = Dense(256)(drop1)\n",
    "    act2 = LeakyReLU(0.1)(dense2)\n",
    "    drop2 = Dropout(0.5)(act2)\n",
    "    \n",
    "    skip1 = Add()([drop1, drop2])\n",
    "    \n",
    "    dense3 = Dense(256)(skip1)\n",
    "    act3 = LeakyReLU(0.1)(dense3)\n",
    "    drop3 = Dropout(0.5)(act3)\n",
    "    \n",
    "    skip2 = Add()([drop1, drop3])\n",
    "    \n",
    "    dense4 = Dense(256)(skip2)\n",
    "    act4 = LeakyReLU(0.1)(dense4)\n",
    "    drop4 = Dropout(0.5)(act4)\n",
    "    \n",
    "    skip3 = Add()([drop1, drop4])\n",
    "    \n",
    "    dense5 = Dense(256)(skip3)\n",
    "    act5 = LeakyReLU(0.1)(dense5)\n",
    "    drop5 = Dropout(0.5)(act5)\n",
    "    \n",
    "    skip4 = Add()([drop1, drop5])\n",
    "    \n",
    "    dense6 = Dense(128)(skip4)\n",
    "    act6 = LeakyReLU(0.1)(dense6)\n",
    "    \n",
    "    out = Dense(1, activation='sigmoid')(act6)\n",
    "    \n",
    "    model = Model(inputs = [inp1,inp2], outputs = out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4e672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
